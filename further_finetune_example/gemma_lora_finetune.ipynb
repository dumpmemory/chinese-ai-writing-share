{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP40T+t4kJwvlkyI3P7cuAc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0fa23f661f64016a3989ec023475440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2deac2ac12ad47c7bb0cf08877ead70e",
              "IPY_MODEL_e8d26cb7a54145c4a26b4f3868de5717",
              "IPY_MODEL_88ca25cae9c240dd83672322afd6f7b7"
            ],
            "layout": "IPY_MODEL_89327a57e7014b538b4ebf9594719013"
          }
        },
        "2deac2ac12ad47c7bb0cf08877ead70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f03214fe0c4f9dba21538304bb93dd",
            "placeholder": "​",
            "style": "IPY_MODEL_f1f5f5e0cc904bdbaa8ce6692a31fe7b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e8d26cb7a54145c4a26b4f3868de5717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d2938a1a794945b980199013b1b429",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ee19d51d0a4437d927c477d5d493d44",
            "value": 4
          }
        },
        "88ca25cae9c240dd83672322afd6f7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7574f074a7be4ce5ba83b323f22355b0",
            "placeholder": "​",
            "style": "IPY_MODEL_10e3d83fa9324f6b8f8aa073f73acbac",
            "value": " 4/4 [00:11&lt;00:00,  2.54s/it]"
          }
        },
        "89327a57e7014b538b4ebf9594719013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f03214fe0c4f9dba21538304bb93dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f5f5e0cc904bdbaa8ce6692a31fe7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33d2938a1a794945b980199013b1b429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ee19d51d0a4437d927c477d5d493d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7574f074a7be4ce5ba83b323f22355b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10e3d83fa9324f6b8f8aa073f73acbac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cef99e8f49c4b70903a7ed60e6a0898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf2e40f63e214ece9fedd345b77f4b26",
              "IPY_MODEL_420c181738bb48e7b9de0e44777f80aa",
              "IPY_MODEL_6539c48d760141a5a827408758510d1b"
            ],
            "layout": "IPY_MODEL_26d0cf0f986a46c690cf090ada150bbf"
          }
        },
        "bf2e40f63e214ece9fedd345b77f4b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff462b4eb124b4396ebcdad83331aec",
            "placeholder": "​",
            "style": "IPY_MODEL_64525fae7c4043798fd3e3b88bc9a02c",
            "value": "Map: 100%"
          }
        },
        "420c181738bb48e7b9de0e44777f80aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21a26b5053cf41c6a31db486929f7d6d",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e84a0d332d9a47258c002aafd62e8432",
            "value": 5000
          }
        },
        "6539c48d760141a5a827408758510d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad84733f490449ca3beb1f49c1d5c04",
            "placeholder": "​",
            "style": "IPY_MODEL_efd6a1b4c0da4baf99a549697fa5ff3e",
            "value": " 5000/5000 [00:01&lt;00:00, 5153.11 examples/s]"
          }
        },
        "26d0cf0f986a46c690cf090ada150bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff462b4eb124b4396ebcdad83331aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64525fae7c4043798fd3e3b88bc9a02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21a26b5053cf41c6a31db486929f7d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84a0d332d9a47258c002aafd62e8432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ad84733f490449ca3beb1f49c1d5c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd6a1b4c0da4baf99a549697fa5ff3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hululuzhu/chinese-ai-writing-share/blob/main/further_finetune_example/gemma_lora_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemma + LoRA = Finetune on Consumer level GPU\n",
        "- branched from my own [llama finetune repo](https://github.com/hululuzhu/llama-lora-chinese-couplet)\n",
        "- Last update: 02/21/2024\n",
        "- Contact: hululu.zhu@gmail.com\n",
        "- **TODO: make sure the tokens match Gemma settings**\n",
        "\n",
        "\n",
        "Zero-shot Examples\n",
        "- after 2 epochs of 5k pairs, cap max tokens, greedy\n",
        "- post-processing to match # of chinese chars\n",
        "- ideally a well trained model will know end of sentence (eos) itself\n",
        "- prompt: `对联：{上联}\\n下联：`\n",
        "\n"
      ],
      "metadata": {
        "id": "dc7pi1lcUGEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "- Nvidia GPU, check if 10G HBM (High Bandwidth Memory) ram available\n",
        "- pip install software"
      ],
      "metadata": {
        "id": "JmJQAx79UhwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umlSDnCYaFLf",
        "outputId": "76701a98-49b1-4d3a-f6f0-76bfaef64d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-0ef16b0b-1c3e-c7e9-13d1-bc4d3c9ba230)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CorDyq5oT4nm",
        "outputId": "1addafe8-74dc-4a49-dc91-14ad09e014b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total memory: 16106127360\n",
            "Free memory: 15835529216\n",
            "Used memory: 270598144\n"
          ]
        }
      ],
      "source": [
        "!pip install -q nvidia-ml-py3\n",
        "import nvidia_smi\n",
        "nvidia_smi.nvmlInit()\n",
        "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
        "# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
        "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "nvidia_smi.nvmlShutdown()\n",
        "\n",
        "print(\"Total memory:\", info.total)\n",
        "print(\"Free memory:\", info.free)\n",
        "print(\"Used memory:\", info.used)\n",
        "\n",
        "assert info.free > 1e10, (\n",
        "    \"Looks like your GPU is busy or not having enough 10G memory to continue\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As of 02/21/2024, we need latest transformer to pick up Gemma tokenizer\n",
        "# Note we might need restart the instance to pick the changes\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q datasets loralib sentencepiece\n",
        "!pip install -q peft"
      ],
      "metadata": {
        "id": "ZaI5k-QZUqV0",
        "outputId": "22c73be6-f37f-4f2f-cbb2-5481ac7a39a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All the Imports"
      ],
      "metadata": {
        "id": "PClCVhTSUsWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# disable warnings unless needed\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "xU4z0tNhas13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, load_dataset\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "from peft import PeftModel, get_peft_config, get_peft_model, LoraConfig, TaskType, prepare_model_for_int8_training\n",
        "import pickle\n",
        "import sys\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, AutoModelForSeq2SeqLM, DataCollatorForLanguageModeling"
      ],
      "metadata": {
        "id": "JTfioe8DUrro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define top-level configs"
      ],
      "metadata": {
        "id": "B5UflVhwVCRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your model\n",
        "# MODEL = \"llama-1-7b\"  #@param [\"llama-1-7b\", \"llama-2-7b\", \"llama-2-7b-chat\"]\n",
        "MODEL = \"gg-hf/gemma-7b-it\"\n",
        "model_name_or_path = MODEL\n",
        "tokenizer_name_or_path = MODEL\n",
        "\n",
        "# Max num of tokens (including prompt and output), chinese encoding takes more\n",
        "# than # of chars as observed\n",
        "CUTOFF_LEN = 96\n",
        "# Predict training prompt as well to increase quality as Alpaca Lora does.\n",
        "# Turn off to speedup, but might affect quality.\n",
        "TRAIN_ON_INPUT = True"
      ],
      "metadata": {
        "id": "e0sCGL2FVFsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required to login to get gemma checkpoints\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "x1O0bVvJ-yN9",
        "outputId": "ec742616-c26f-4ea3-849c-e6a2cd9d8ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# Somehow Gemma takes way more memory than llama2, why why?\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b-it\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b-it\",\n",
        "                                            #  device_map=\"auto\",\n",
        "                                            #  load_in_8bit=True, # 8bit seems to take more than 9G memory...\n",
        "                                            quantization_config=quantization_config,)\n"
      ],
      "metadata": {
        "id": "gYJtQqOL-dPs",
        "outputId": "1f192df0-28c1-4826-c2d6-55f613429cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "b0fa23f661f64016a3989ec023475440",
            "2deac2ac12ad47c7bb0cf08877ead70e",
            "e8d26cb7a54145c4a26b4f3868de5717",
            "88ca25cae9c240dd83672322afd6f7b7",
            "89327a57e7014b538b4ebf9594719013",
            "d5f03214fe0c4f9dba21538304bb93dd",
            "f1f5f5e0cc904bdbaa8ce6692a31fe7b",
            "33d2938a1a794945b980199013b1b429",
            "1ee19d51d0a4437d927c477d5d493d44",
            "7574f074a7be4ce5ba83b323f22355b0",
            "10e3d83fa9324f6b8f8aa073f73acbac"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0fa23f661f64016a3989ec023475440"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO check if this right, copied from llama\n",
        "tokenizer.pad_token_id = 0\n",
        "tokenizer.padding_side = \"left\"  # Allow batched inference"
      ],
      "metadata": {
        "id": "An07i1R_VS43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Training data"
      ],
      "metadata": {
        "id": "o_buRbJqV6m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse my T5 couplet data code https://github.com/hululuzhu/chinese-ai-writing-share/blob/main/training/t5_finetune/Mengzi_T5_Finetune_Chinese_Couplet_V1.ipynb\n",
        "working_dir = \"/tmp/working_dir\"\n",
        "!mkdir -p {working_dir}\n",
        "!wget https://github.com/wb14123/couplet-dataset/releases/download/1.0/couplet.tar.gz -P {working_dir}\n",
        "!ls -l {working_dir}\n",
        "!mkdir -p {working_dir}/couplet_files\n",
        "!tar -xf {working_dir}/couplet.tar.gz -C {working_dir}/couplet_files\n",
        "!head -1 {working_dir}/couplet_files/couplet/train/in.txt {working_dir}/couplet_files/couplet/train/out.txt\n",
        "\n",
        "COUPLET_PATH = f'{working_dir}/couplet_files/couplet'\n",
        "MAX_SEQ_LEN = 32  # Max 32 chinese char including punctuation marks\n",
        "\n",
        "train_df, test_df = None, None\n",
        "for t in ['train', 'test']:\n",
        "  ins, outs = [], []\n",
        "  for i in ['in', 'out']:\n",
        "    with open(f\"{COUPLET_PATH}/{t}/{i}.txt\", \"r\") as f:\n",
        "      for line in f:\n",
        "        clean_line = line.strip().replace(' ', '').replace('\\n', '').replace('\\r', '')[:MAX_SEQ_LEN]\n",
        "        if i=='in':\n",
        "          ins.append(clean_line)\n",
        "        else:\n",
        "          outs.append(clean_line)\n",
        "  # The column names to match simpleT5\n",
        "  data_dict = {\n",
        "      'source_text': ins,\n",
        "      'target_text': outs,\n",
        "  }\n",
        "  if t == 'train':\n",
        "    train_df = pd.DataFrame(data_dict)\n",
        "  else:\n",
        "    test_df = pd.DataFrame(data_dict)\n",
        "\n",
        "COUPLET_PROMPOT = '对联：'\n",
        "COUPLET_SUFFIX = '\\n下联：'\n",
        "train_df['source_text'] = COUPLET_PROMPOT + train_df['source_text'] + COUPLET_SUFFIX\n",
        "test_df['source_text'] = COUPLET_PROMPOT + test_df['source_text'] + COUPLET_SUFFIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsi0FxcGV8PF",
        "outputId": "c860452f-9e71-453e-b427-35ecadcf8562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-22 04:22:35--  https://github.com/wb14123/couplet-dataset/releases/download/1.0/couplet.tar.gz\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/122695108/9643dda6-194e-11e8-9642-44c7d57d40ac?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240222%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240222T042050Z&X-Amz-Expires=300&X-Amz-Signature=d33d16a9ba8242ef7c963f185e1d9cad2d5b85e109cca268794abb86e2beaf3a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=122695108&response-content-disposition=attachment%3B%20filename%3Dcouplet.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-02-22 04:22:35--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/122695108/9643dda6-194e-11e8-9642-44c7d57d40ac?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240222%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240222T042050Z&X-Amz-Expires=300&X-Amz-Signature=d33d16a9ba8242ef7c963f185e1d9cad2d5b85e109cca268794abb86e2beaf3a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=122695108&response-content-disposition=attachment%3B%20filename%3Dcouplet.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27412598 (26M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/working_dir/couplet.tar.gz.4’\n",
            "\n",
            "couplet.tar.gz.4    100%[===================>]  26.14M  51.5MB/s    in 0.5s    \n",
            "\n",
            "2024-02-22 04:22:36 (51.5 MB/s) - ‘/tmp/working_dir/couplet.tar.gz.4’ saved [27412598/27412598]\n",
            "\n",
            "total 133864\n",
            "drwxr-xr-x 3 root root     4096 Feb 22 04:08 couplet_files\n",
            "-rw-r--r-- 1 root root 27412598 Dec  6  2021 couplet.tar.gz\n",
            "-rw-r--r-- 1 root root 27412598 Dec  6  2021 couplet.tar.gz.1\n",
            "-rw-r--r-- 1 root root 27412598 Dec  6  2021 couplet.tar.gz.2\n",
            "-rw-r--r-- 1 root root 27412598 Dec  6  2021 couplet.tar.gz.3\n",
            "-rw-r--r-- 1 root root 27412598 Dec  6  2021 couplet.tar.gz.4\n",
            "==> /tmp/working_dir/couplet_files/couplet/train/in.txt <==\n",
            "晚 风 摇 树 树 还 挺 \n",
            "\n",
            "==> /tmp/working_dir/couplet_files/couplet/train/out.txt <==\n",
            "晨 露 润 花 花 更 红 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 5k\n",
        "train_df_sample = train_df[['source_text', 'target_text']].sample(5000)\n",
        "train_df_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "vFVQGl_AWQf-",
        "outputId": "80332a23-16ce-4363-fe9d-fbfe64e1ce27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       source_text         target_text\n",
              "138048             对联：柴扉半掩云深处\\n下联：             僧客迟归日暮时\n",
              "552529             对联：卅年梦寐惊回首\\n下联：             一样亭台只断肠\n",
              "597006               对联：竹报平安户\\n下联：               花开富贵门\n",
              "567235             对联：豪啸松间风壮意\\n下联：             苦吟月下酒抒怀\n",
              "734209             对联：竹林踏月独醉我\\n下联：             梅海迎风自迷予\n",
              "...                            ...                 ...\n",
              "326710             对联：莫姿高情求逸思\\n下联：             只缘幽恨在新诗\n",
              "42032   对联：沉毅自从容，生死关头，结成屏障横山势\\n下联：  舒张原有度，烽烟散后，响起驼铃大漠声\n",
              "75045         对联：眸前旋转通天塔，撩人望日\\n下联：        域外飞来作地标，煮海听涛\n",
              "235626  对联：茶艺道行深，红炉煮出一壶诗，谁为高手\\n下联：  茗乡文化厚，绿袖斟来千尺瀑，我上奖台\n",
              "436761              对联：浪荡也属添乱\\n下联：              潮湿未必拍拖\n",
              "\n",
              "[5000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57c1126c-d99b-4fa4-940a-998be8fe2a7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>138048</th>\n",
              "      <td>对联：柴扉半掩云深处\\n下联：</td>\n",
              "      <td>僧客迟归日暮时</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552529</th>\n",
              "      <td>对联：卅年梦寐惊回首\\n下联：</td>\n",
              "      <td>一样亭台只断肠</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597006</th>\n",
              "      <td>对联：竹报平安户\\n下联：</td>\n",
              "      <td>花开富贵门</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567235</th>\n",
              "      <td>对联：豪啸松间风壮意\\n下联：</td>\n",
              "      <td>苦吟月下酒抒怀</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734209</th>\n",
              "      <td>对联：竹林踏月独醉我\\n下联：</td>\n",
              "      <td>梅海迎风自迷予</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326710</th>\n",
              "      <td>对联：莫姿高情求逸思\\n下联：</td>\n",
              "      <td>只缘幽恨在新诗</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42032</th>\n",
              "      <td>对联：沉毅自从容，生死关头，结成屏障横山势\\n下联：</td>\n",
              "      <td>舒张原有度，烽烟散后，响起驼铃大漠声</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75045</th>\n",
              "      <td>对联：眸前旋转通天塔，撩人望日\\n下联：</td>\n",
              "      <td>域外飞来作地标，煮海听涛</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235626</th>\n",
              "      <td>对联：茶艺道行深，红炉煮出一壶诗，谁为高手\\n下联：</td>\n",
              "      <td>茗乡文化厚，绿袖斟来千尺瀑，我上奖台</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436761</th>\n",
              "      <td>对联：浪荡也属添乱\\n下联：</td>\n",
              "      <td>潮湿未必拍拖</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57c1126c-d99b-4fa4-940a-998be8fe2a7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57c1126c-d99b-4fa4-940a-998be8fe2a7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57c1126c-d99b-4fa4-940a-998be8fe2a7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e5c08f29-63c7-4ba8-8157-6aeb0e9fcd35\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5c08f29-63c7-4ba8-8157-6aeb0e9fcd35')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e5c08f29-63c7-4ba8-8157-6aeb0e9fcd35 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_736021f1-42fe-42ce-abdc-59c5fcb3891a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df_sample')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_736021f1-42fe-42ce-abdc-59c5fcb3891a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df_sample');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df_sample",
              "summary": "{\n  \"name\": \"train_df_sample\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"source_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4961,\n        \"samples\": [\n          \"\\u5bf9\\u8054\\uff1a\\u5f69\\u7fbd\\u821e\\u9752\\u971e\\uff0c\\u542c\\u4e09\\u664b\\u6625\\u96f7\\uff0c\\u4e5d\\u5929\\u97f6\\u4e50\\n\\u4e0b\\u8054\\uff1a\",\n          \"\\u5bf9\\u8054\\uff1a\\u4fd7\\u4e16\\u5531\\u7f62\\u6c5f\\u6e56\\u68a6\\n\\u4e0b\\u8054\\uff1a\",\n          \"\\u5bf9\\u8054\\uff1a\\u6ee1\\u5cad\\u79cb\\u67ab\\u6731\\u4e3d\\u53f6\\n\\u4e0b\\u8054\\uff1a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4993,\n        \"samples\": [\n          \"\\u98de\\u71d5\\u4ece\\u65e0\\u8001\\u9053\\u5acc\",\n          \"\\u54c1\\u8d28\\u9053\\u5fb7\\u4e0e\\u65e5\\u589e\",\n          \"\\u4e09\\u8a00\\u6709\\u9053\\u662f\\u540d\\u7bc7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Data to Training-friendly DataSet"
      ],
      "metadata": {
        "id": "6b8QLu8UXafg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copied from Alpaca-LoRA, notice input_ids, attention_mask, and labels are\n",
        "# default expected columns in huggingface dataset lib\n",
        "def tokenize(tokenizer, prompt, cutoff_len, add_eos_token=True):\n",
        "  # there's probably a way to do this with the tokenizer settings\n",
        "  # but again, gotta move fast\n",
        "  result = tokenizer(\n",
        "      prompt,\n",
        "      truncation=True,\n",
        "      max_length=cutoff_len,\n",
        "      padding=False,\n",
        "      return_tensors=None,\n",
        "  )\n",
        "  if (\n",
        "      result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
        "      and len(result[\"input_ids\"]) < cutoff_len\n",
        "      and add_eos_token\n",
        "  ):\n",
        "    result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
        "    result[\"attention_mask\"].append(1)\n",
        "\n",
        "  # result[\"labels\"] = copy.deepcopy(result[\"input_ids\"])\n",
        "  result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "  return result\n",
        "\n",
        "\n",
        "# Branched from Alpaca-LoRA\n",
        "def tokenize_fn(data_point):\n",
        "  prompt_in, prompt_out = data_point['source_text'], data_point['target_text']\n",
        "  full_prompt = prompt_in + prompt_out\n",
        "  tokenized_full_prompt = tokenize(tokenizer, full_prompt, CUTOFF_LEN)\n",
        "  if not TRAIN_ON_INPUT:\n",
        "    user_prompt = prompt_in\n",
        "    tokenized_user_prompt = tokenize(tokenizer, user_prompt, CUTOFF_LEN, add_eos_token=False)\n",
        "    user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
        "    tokenized_full_prompt[\"labels\"] = [\n",
        "        -100 # special id for skipping\n",
        "    ] * user_prompt_len + tokenized_full_prompt[\"labels\"][user_prompt_len:]\n",
        "  return tokenized_full_prompt\n",
        "\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df_sample)\n",
        "train_ds = train_ds.flatten()\n",
        "tokenized_train_ds = train_ds.map(\n",
        "    tokenize_fn,\n",
        "    remove_columns=['source_text', 'target_text', '__index_level_0__'],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3cef99e8f49c4b70903a7ed60e6a0898",
            "bf2e40f63e214ece9fedd345b77f4b26",
            "420c181738bb48e7b9de0e44777f80aa",
            "6539c48d760141a5a827408758510d1b",
            "26d0cf0f986a46c690cf090ada150bbf",
            "6ff462b4eb124b4396ebcdad83331aec",
            "64525fae7c4043798fd3e3b88bc9a02c",
            "21a26b5053cf41c6a31db486929f7d6d",
            "e84a0d332d9a47258c002aafd62e8432",
            "3ad84733f490449ca3beb1f49c1d5c04",
            "efd6a1b4c0da4baf99a549697fa5ff3e"
          ]
        },
        "id": "bi6C8fsIWVkM",
        "outputId": "1f886809-479b-44ac-ea6f-06dc70d588d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cef99e8f49c4b70903a7ed60e6a0898"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally check a few examples by decoding the inputs\n",
        "for i in range(100, 103):\n",
        "  print(\"token length\", len(tokenized_train_ds['input_ids'][i]))\n",
        "  print(tokenizer.decode(tokenized_train_ds['input_ids'][i]))\n",
        "  print(\"Label ids\", tokenized_train_ds['labels'][i])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq129F2LXlRV",
        "outputId": "d9b8809f-428b-4296-f18f-47d7dbd8cdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token length 12\n",
            "<bos>对联：闪电\n",
            "下联：鸣雷<eos>\n",
            "Label ids [2, 235735, 236612, 235465, 199171, 108, 235543, 236612, 235465, 239369, 237184, 1]\n",
            "\n",
            "token length 22\n",
            "<bos>对联：群蜂起舞争风采\n",
            "下联：一马当先赛水平<eos>\n",
            "Label ids [2, 235735, 236612, 235465, 236783, 239137, 235803, 236993, 237124, 236229, 237266, 108, 235543, 236612, 235465, 235411, 236502, 235804, 235938, 237013, 50499, 1]\n",
            "\n",
            "token length 21\n",
            "<bos>对联：二分明月怀中寄\n",
            "下联：十里春风面上柔<eos>\n",
            "Label ids [2, 235735, 236612, 235465, 235796, 186144, 235612, 237810, 235493, 237585, 108, 235543, 236612, 235465, 235905, 235792, 236544, 236229, 100079, 237640, 1]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA setup\n",
        "- Check out LoRA paper\n",
        "- Why q_proj and v_proj?\n",
        "  - ![](https://lh3.googleusercontent.com/pG1o98-ZuTdvGaIuf3r0_GQ2wqZv1eAjaM13ki_AoipSm4Vo0v3JCynmU26PjE_6qKvyLdiDlZfQP8mGpvy0hG6TMDM-ROpup35WYmH3lBiGVC67tQL2kZnNIVzz0gviU88lq7yP126N1DCaKxkvXd1vE5TBwasBTH2waI_QbcyT324snp5iOCJXDrMa9bPokbM4w8PwJL61lqfGXmOvbP2Yqo5gOC7kA73aZPMOG3CnWzFujZpbQ5so7ZnHNOvmBWSjKUHvqI8UbvJvAy43SXL2UePcFg-KcWAA9gCUscNxKOOtai0_6ShZgZLCXCMLvLYpbqK6IqtYTS7-dwQMYQrRJ80IyPxMYwfSLaYn2UVd0I04ETFCqOH-pDtsToZ3eCGqQi-zxLdcDUpqhcXxj60PjxpMOyFK_wCK1tKEx7hu7nUDR4GYIIRFtNZS_jMhFaKhqcZf6d3Vora-2v0Sv_CVhDTy5cabVpSDEqBWpGMiCcj5IvnBIRAkPY5D_Mr5elWSCuanOXMp9riwK2-WobJoNvW7qATFAr3aiTA5MCQPqwvkOXhpj9YF7QudshxaplDzpBiLxJbdvzE-froAlxAup2yDEhEOb_xuvRBLetvL366GOEivlq577Y8MTusVcz_b9ex6TP77_XjRHAp4lQ7Bs7tR2tjY-n29bC1MhGB_t7Ta82MdLivR-T5lG4hvhGJ-rTsqMkUm0KY-Vqup-04eZHBMkY1RHjj7oNc8vDXHbTiFskLfne5Trr0_3MCZamyRZuwPeZXzFlzbif1lSBwXpSk0ckzPMGRFhiDZ0sa3QUrLeyvGA5UzHIhqHL0Ve-f03V0z48o_YoHSdWrhN8xZJb6ga-eGu0MM9f5VxE7Y9znQ4qE9_5neS6GBHvA0-YXjzZ7INP9KVgKpX_FTuAuegL7ARB1gG4lbXKWVKQS38g=w1577-h337-s-no?authuser=0)\n",
        "- why r=16 (>=8)\n",
        "  - ![](https://lh3.googleusercontent.com/sxLGQpoBbmjnZwK853wFOcgEgzvJIa7wOpaH72v1eNw9gI9VaMvhpWGhzPCPowSuG44wzO53ENrXGMrdoXXhTjPmy1jRVvAMqbFYiwcCU4sZ0jqOe2vP1I9hEw-syKqpPW1-Nr5TM10Qm8MYXuigatFPNl76FSxYXBRHNcZRjeluGPxMjz78SXzBa07j6YomCGQJCyx5QTRVfhWw7iy4dbb1rybldeodUvY1xI8XzTzQeclYhE8kLI6yN7J02LKpkhHmzMgFY0Qr73gvoINGmZyguJItJ0ZcaR3zBJNfIIaBSaYe3amB4qL7zWu6sYOxfdBk8v_lWLCCTys1_ThFoiUhLDrHRK1LX5QELQTf_MAlFVk5qisF2dZo3GFEt5bKga2CNwSH-I5FjL9Z6jnopRDHCs1JGVmYn6sgdLhrG7fbj83hAb5NLwSfebi5pjYRASAVVC18hNo1ZkG_TCTPJv2__KveWNjalDkSWWEVzMZO6ZlnoLMtwEA_KfqaDNEdVTs2wa_-dsbXijPDkF0bSdiDqtiAe6Nk_sL1iEoNMswMvCGOD5orD4oojigkteh-xdyaQ3W0mEqC3HXEaPAAKHQOp2V5XBIMi-wIo_M-bjK304SA68jvmizpyYTI-yTiAb_B8lUR0PeAMp1avZux4NdXVZZu1wWlzgpr3HC7pU7ZmqgO_xJrU-ICMrkeqy8eYOy-jy1NrK03Y9NsT7-JTxg5HHGBptMKkJORT7IIQRl_eCgw0WMu9Bc9ueSIbSCLQgZ_WdaMe3wSjLkj8NmRgQ83HW686Ww54xfwscMq8l97MgaJobKqRvagOzx2KG_cMthGWfkIqVFCdfTgBv3c8Mf7lBDwduxsyfNbLuPSxW_NI4UmxN7Tkx5xN_qBBI5prltAYX_jYhFtq6JNd2bnWgqDBfDDkHp96Wj3kMRF43A8sw=w1804-h507-s-no?authuser=0)"
      ],
      "metadata": {
        "id": "_wcnKGeNXwCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_int8_training(model)\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32, # scaling param related to r, reuse alpaca-lora\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(model, config)"
      ],
      "metadata": {
        "id": "TTul-gBRXvVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "- Show before and after!"
      ],
      "metadata": {
        "id": "5T1SU9JkYxmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out meaning of the Chinese char using ChatGPT\n",
        "def eval_model(my_model, examples=[\"上联：春风得意花铺路\\n下联：\",\n",
        "                                   \"上联：美丽中国魅力北京\\n下联：\",\n",
        "                                   \"上联：鱼书千里梦\\n下联：\",\n",
        "                                   \"对联：日落晚霞临古寺\\n下联：\",]):\n",
        "  for p_in in examples:\n",
        "    batch = tokenizer(\n",
        "        p_in,\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "    with torch.cuda.amp.autocast(): # required for mixed precisions\n",
        "      output_tokens = my_model.generate(\n",
        "          **batch, max_new_tokens=batch['input_ids'].shape[-1])\n",
        "    # print(output_tokens[0])\n",
        "    out = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
        "    # My own post-processing logic to \"cheat\" to align chars\n",
        "    if len(out) > len(p_in) * 2 - 7:\n",
        "      out = out[:len(p_in) * 2 - 7 - len(out)] # perfectly match chars\n",
        "    # replace the last N for visibility\n",
        "    if out.count('\\n') > 1:\n",
        "      out = out[::-1].replace(\"\\n\", \"n\\\\\", 1)[::-1]\n",
        "    print(out)\n",
        "    print()"
      ],
      "metadata": {
        "id": "wxCMYMcF4IRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Different GPUs may give out slightly different answers below due to very small precision difference\n",
        "print(\"Before training\")\n",
        "eval_model(lora_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMfEwhTfY0NC",
        "outputId": "d66ddf79-715c-4b82-eb6b-2951b1a8dee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before training\n",
            "上联：春风得意花铺路\n",
            "下联：花香满鼻，春暖\n",
            "\n",
            "上联：美丽中国魅力北京\n",
            "下联：中国传统建筑风格\n",
            "\n",
            "上联：鱼书千里梦\n",
            "下联：笑口在笑。\n",
            "\n",
            "对联：日落晚霞临古寺\n",
            "下联：花香满院，迎风\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "LZmFMCf8Dfkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As you can tell, I even omitted eval_dataset for this demo :(\n",
        "trainer = transformers.Trainer(\n",
        "    model=lora_model,\n",
        "    train_dataset=tokenized_train_ds,\n",
        "    args=transformers.TrainingArguments(\n",
        "        # increased batch size will significantly increase GPU requirement here\n",
        "        # Decrease to 4 if you have less than 16G vram\n",
        "        # Batch = 4, probably 8.3-8.8G vram\n",
        "        # Batch = 16, 9.5G+\n",
        "        # Batch = 32, 11G+\n",
        "        # Batch = 64, 14G+\n",
        "        per_device_train_batch_size=4,\n",
        "        gradient_accumulation_steps=2,\n",
        "        warmup_steps=8,\n",
        "        num_train_epochs=2,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=20,\n",
        "        output_dir='outputs',\n",
        "        remove_unused_columns=False,\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForSeq2Seq(\n",
        "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True,\n",
        "    ),\n",
        ")\n",
        "lora_model.config.use_cache = False # Alpaca Lora sets this for training\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "yb7K0PsYY6T3",
        "outputId": "c4783c4d-b593-48db-c35d-20a1178226e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='206' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 206/1250 12:59 < 1:06:27, 0.26 it/s, Epoch 0.33/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>30.785400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>14.341900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>5.215000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>4.839200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.569900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>4.431900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>4.551500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>4.464600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>4.356600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.317200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Empirical quick tests showed \"somehow ok\" results if loss < THRESHOLD\n",
        "print(\"After training\")\n",
        "eval_model(lora_model)"
      ],
      "metadata": {
        "id": "xilHS3n9ZKj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Suggested additional reading\n",
        "- [Decoding algorithm by HF](https://huggingface.co/blog/how-to-generate)\n",
        "- So far, I only demoed greedy search (output token with highest prob at each position without looking ahead)"
      ],
      "metadata": {
        "id": "p8CQ4NrklkLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Upload to HuggingFace and share with the world!\n",
        "- And you should!"
      ],
      "metadata": {
        "id": "c1qHzgL9ZPU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()\n",
        "# YOUR_HF_ID = \"YOUR_ID_PLZ\"\n",
        "# lora_model.push_to_hub(f\"{YOUR_HF_ID}/chinese-couplet-gemma-lora-test-v0.1\",\n",
        "#                        use_auth_token=True,\n",
        "#                        create_pr=True)\n",
        "# # Go to huggingface and merge the PR to share with the world!"
      ],
      "metadata": {
        "id": "Zept7b_5ZUbX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}