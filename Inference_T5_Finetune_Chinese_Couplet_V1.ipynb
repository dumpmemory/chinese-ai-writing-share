{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference T5 Finetune Chinese Couplet V1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPf16YtZUkaBw6TWHNwVB0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hululuzhu/chinese-ai-writing-share/blob/main/Inference_T5_Finetune_Chinese_Couplet_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference for models trained from [T5 chinese couplet training colab](https://github.com/hululuzhu/chinese-ai-writing-share/blob/main/Mengzi_T5_Finetune_Chinese_Couplet_V1.ipynb)\n",
        "- Download my saved models at [drive link](https://drive.google.com/drive/folders/1bQb_nrHHLkDYj09P2rrX7PSvHD8h3cTx?usp=sharing)"
      ],
      "metadata": {
        "id": "IsQADAHEdrEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load package and previously trained models"
      ],
      "metadata": {
        "id": "i_0LZLuCd0XX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5mNUEaT_bzWu"
      },
      "outputs": [],
      "source": [
        "# Quite install simple T5 package\n",
        "!pip install -q simplet5 &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rH9CaTNb-Hg",
        "outputId": "2e9890f2-267d-4bbc-d75b-ba9ab9f4d1ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p my_t5/finetuned\n",
        "!cp /content/drive/MyDrive/ML/Models/t5-couplet/simplet5-epoch-2-train-loss-3.126/* my_t5/finetuned"
      ],
      "metadata": {
        "id": "fsQmKxtMcDof"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls my_t5/finetuned -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q1Ulu7ucZYv",
        "outputId": "b3b1df10-dc8e-4e27-bb73-b57651bc2e50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 967956\n",
            "-rw------- 1 root root       706 Feb  7 20:51 config.json\n",
            "-rw------- 1 root root 990438349 Feb  7 20:51 pytorch_model.bin\n",
            "-rw------- 1 root root      1786 Feb  7 20:51 special_tokens_map.json\n",
            "-rw------- 1 root root    725135 Feb  7 20:51 spiece.model\n",
            "-rw------- 1 root root      1961 Feb  7 20:51 tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from simplet5 import SimpleT5\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "class MengziSimpleT5(SimpleT5):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    self.device = torch.device(\"cuda\")\n",
        "\n",
        "  def load_my_model(self, use_gpu: bool = True):\n",
        "    self.tokenizer = T5Tokenizer.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(\"my_t5/finetuned\")"
      ],
      "metadata": {
        "id": "fVcInEjtccR1",
        "outputId": "289fd487-3491-4d68-c01c-17c85f64b02b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MengziSimpleT5()\n",
        "model.load_my_model()\n",
        "model.model = model.model.to('cuda')\n",
        "\n",
        "COUPLET_PROMPOT = '对联：'\n",
        "MAX_SEQ_LEN = 32\n",
        "MAX_OUT_TOKENS = MAX_SEQ_LEN\n",
        "\n",
        "def predict_now(in_str, model=model):\n",
        "  model.model = model.model.to('cuda')\n",
        "  in_request = f\"{COUPLET_PROMPOT}{in_str[:MAX_SEQ_LEN]}\"\n",
        "  print(f\"上： {in_str}\\n下：\", model.predict(\n",
        "      in_request,\n",
        "      max_length=MAX_OUT_TOKENS,\n",
        "      num_beams=1,\n",
        "      top_p=1.0,\n",
        "      top_k=1,\n",
        "      do_sample=False)[0]) # topp, num_beams ..."
      ],
      "metadata": {
        "id": "n5zWCQa0cjWc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference now\n",
        "- Note we turned off sampling to see determistic results for comparison"
      ],
      "metadata": {
        "id": "fYLkzlt4d4DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Epoch 3:\\n\")\n",
        "for pre in ['欢天喜地度佳节', '不待鸣钟已汗颜，重来试手竟何艰',\n",
        "            '当年欲跃龙门去，今日真披马革还', '载歌在谷',\n",
        "            '北国风光，千里冰封，万里雪飘',\n",
        "            '独立寒秋，湘江北去，橘子洲头']:\n",
        "  predict_now(pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6DwGQSbdDtj",
        "outputId": "4fbf0cfc-bae6-45ab-d9b2-e9d09a4b505a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "\n",
            "上： 欢天喜地度佳节\n",
            "下： 笑语欢歌迎新春\n",
            "上： 不待鸣钟已汗颜，重来试手竟何艰\n",
            "下： 何须击鼓犹昂首?再起杀心应有功\n",
            "上： 当年欲跃龙门去，今日真披马革还\n",
            "下： 今日欲乘虎势来,明朝又见马蹄飞\n",
            "上： 载歌在谷\n",
            "下： 对酒当歌\n",
            "上： 北国风光，千里冰封，万里雪飘\n",
            "下： 南疆气象,一城春暖?八方客来\n",
            "上： 独立寒秋，湘江北去，橘子洲头\n",
            "下： 孤眠冷月,玉笛西来?琵琶指间\n"
          ]
        }
      ]
    }
  ]
}