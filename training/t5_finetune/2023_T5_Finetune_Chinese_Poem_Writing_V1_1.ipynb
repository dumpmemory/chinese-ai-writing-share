{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hululuzhu/chinese-ai-writing-share/blob/main/training/t5_finetune/2023_T5_Finetune_Chinese_Poem_Writing_V1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGiExl72jSfD"
      },
      "source": [
        "# T5 写诗\n",
        "- 设计：Pretrained T5 + “写诗 prompt” fine-tuning\n",
        "  - 对比我的 [transformer training from scratch](https://github.com/hululuzhu/chinese-ai-writing-share/blob/main/%E4%B8%AD%E6%96%87%E5%86%99%E8%AF%97Transformer_Source_Code_Share_V1.ipynb)\n",
        "  - 想要加入作者作为可选输入\n",
        "    - 每个文章分两次输入，一次作者名字，一次“None”名字（通用）\n",
        "- 数据：[诗歌github](https://github.com/chinese-poetry/chinese-poetry)\n",
        "- 相关内容\n",
        "  - [Huggingface](https://huggingface.co/)\n",
        "  - LangZhou Chinese [MengZi T5 pretrained Model](https://huggingface.co/Langboat/mengzi-t5-base) and [paper](https://arxiv.org/pdf/2110.06696.pdf)\n",
        "  - [SimpleT5 by Shivanandroy](https://github.com/Shivanandroy/simpleT5) (on top of pytorch and pytorch lightning) and [his awesome medium article](https://medium.com/geekculture/simplet5-train-t5-models-in-just-3-lines-of-code-by-shivanand-roy-2021-354df5ae46ba)\n",
        "- 进度\n",
        "  - 02/2023, improve source text to make it shorter and more concise\n",
        "    - Enforce the alignment of text size in poems\n",
        "  - New model to be trained by 03/2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1qVyC6tqujH"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib8ELKoFPACz"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Jn7mdTkq3Za"
      },
      "outputs": [],
      "source": [
        "IS_TEST_FLOW = False  #@param {type: \"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZR4K8fyO7o3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW3P2Ld9jMLu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "!pip install -q \"tqdm>=4.36.1\" > /tmp/na\n",
        "from tqdm.notebook import tqdm\n",
        "!pip install -q chinese-converter > /tmp/na\n",
        "import chinese_converter  # 繁体到简体需要\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a58tcJKk7ll"
      },
      "outputs": [],
      "source": [
        "# https://github.com/chinese-poetry/chinese-poetry\n",
        "POEM_CONTENT = {\n",
        "    'tang': {\n",
        "        'total': 58,\n",
        "        'pattern': \"https://raw.githubusercontent.com/chinese-poetry/chinese-poetry/master/json/poet.tang.{0}.json\"\n",
        "    },\n",
        "    'song': {\n",
        "        'total': 255,\n",
        "        'pattern': \"https://raw.githubusercontent.com/chinese-poetry/chinese-poetry/master/json/poet.song.{0}.json\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_poems(is_test=True, verbose=True):\n",
        "  df_list = []\n",
        "  for dynasty in POEM_CONTENT:\n",
        "    size = 3 if is_test else POEM_CONTENT[dynasty]['total']\n",
        "    pbar = tqdm(total=size, desc=\"Dynasty \" + dynasty)\n",
        "    for i in range(size):\n",
        "      url = POEM_CONTENT[dynasty]['pattern'].format(i * 1000)\n",
        "      if verbose:\n",
        "        print(f\"download {url} now\")\n",
        "      df_list.append(pd.read_json(url))\n",
        "      pbar.update(1)\n",
        "  return pd.concat(df_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrbtEs6flK24"
      },
      "outputs": [],
      "source": [
        "df = get_poems(is_test=IS_TEST_FLOW, verbose=False)\n",
        "df['concat_paragraphs'] = [''.join(map(str, l)) for l in df['paragraphs']]\n",
        "df = df[['author', 'title', 'concat_paragraphs']]\n",
        "\n",
        "def convert_schinese(tchinese):\n",
        "  return chinese_converter.to_simplified(tchinese)\n",
        "\n",
        "df['s_content'] = df.apply(lambda row: convert_schinese(''.join(row.concat_paragraphs)), axis=1)\n",
        "df['s_title'] = df.apply(lambda row: convert_schinese(''.join(row.title)), axis=1)\n",
        "df['s_author'] = df.apply(lambda row: convert_schinese(''.join(row.author)), axis=1)\n",
        "\n",
        "my_df = df\n",
        "print(\"my_df size\", len(my_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVZrYrYRmBuN"
      },
      "outputs": [],
      "source": [
        "MAX_AUTHOR_CHAR = 4\n",
        "MAX_TITLE_CHAR = 12\n",
        "MIN_CONTENT_CHAR = 20\n",
        "MAX_CONTENT_CHAR = 64\n",
        "BAD_TOKENS = \" ()[]《》（）□{}abcdefgxyz一\"\n",
        "\n",
        "def trim_author_fn(row):\n",
        "  return row.s_author[:MAX_AUTHOR_CHAR]\n",
        "\n",
        "def trim_title_fn(row):\n",
        "  trimed_title = row.s_title[:MAX_TITLE_CHAR]\n",
        "  for b in BAD_TOKENS:\n",
        "    trimed_title = trimed_title.replace(b, \"\")\n",
        "  return trimed_title\n",
        "\n",
        "def trim_content_fn(row):\n",
        "  trimed_content = row.s_content[:MAX_CONTENT_CHAR]\n",
        "  # # End with a period to avoid partial ending to confuse model\n",
        "  for b in BAD_TOKENS:\n",
        "    trimed_content = trimed_content.replace(b, \"\")\n",
        "  last_period = trimed_content.rfind(\"。\")\n",
        "  return trimed_content[:last_period+1]\n",
        "  # return trimed_content\n",
        "\n",
        "# Trim the size, a soft copy to avoid the view/copy conflict warning\n",
        "my_df['s_author_trim'] = my_df.copy().apply(trim_author_fn, axis=1)\n",
        "my_df['s_title_trim'] = my_df.copy().apply(trim_title_fn, axis=1)\n",
        "my_df['s_content_trim'] = my_df.copy().apply(trim_content_fn, axis=1)\n",
        "\n",
        "print(\"my_df size\", len(my_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YlgJ2BznDZE"
      },
      "outputs": [],
      "source": [
        "# Title cannot be empty\n",
        "empty_title_mask = (my_df['s_title_trim'].str.len() == 0)\n",
        "too_short_cotent_mask = (my_df['s_content_trim'].str.len() <= MIN_CONTENT_CHAR)\n",
        "invalid_mask = (('无正文' == my_df['s_content_trim']) | ('无正文' == my_df['s_author_trim']))\n",
        "too_short_mask =  empty_title_mask | too_short_cotent_mask | invalid_mask\n",
        "# filtered_my_df = my_df.loc[too_short_mask]\n",
        "# filtered_my_df\n",
        "\n",
        "my_df = my_df.loc[~too_short_mask][[\n",
        "  's_author_trim', 's_title_trim', 's_content_trim']]\n",
        "print(\"my_df size\", len(my_df))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "result_dict = {\n",
        "    's_author_trim': [],\n",
        "    's_title_trim': [],\n",
        "    's_content_trim': [],\n",
        "}\n",
        "for i, row in my_df.iterrows():\n",
        "  c = row['s_content_trim']\n",
        "  snippets = list(re.split('，|。|？', c))\n",
        "  lens = [len(s) for s in snippets if s.strip() != '']\n",
        "  if max(lens) != min(lens) or max(lens) not in [5, 7]:\n",
        "    continue\n",
        "  result_dict['s_author_trim'].append(row['s_author_trim'])\n",
        "  result_dict['s_title_trim'].append(row['s_title_trim'])\n",
        "  result_dict['s_content_trim'].append(row['s_content_trim'])\n",
        "# print(\"get rid of \", sum(bad_items))\n",
        "my_df = pd.DataFrame(data=result_dict)\n",
        "print(\"left\", len(my_df))"
      ],
      "metadata": {
        "id": "jtJOdJEEsQ1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj00wicXAD5S"
      },
      "outputs": [],
      "source": [
        "my_df.sample(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwLTpqrhAV0H"
      },
      "outputs": [],
      "source": [
        "AUTHOR_PROMPT = \"模仿：\"\n",
        "TITLE_PROMPT = \"作诗：\"\n",
        "EOS_TOKEN = '</s>'\n",
        "def build_dataset_df(df, include_author=True):\n",
        "  dfc = df.copy()\n",
        "  if include_author:\n",
        "    dfc['source_text'] = TITLE_PROMPT + df['s_title_trim'] + EOS_TOKEN + AUTHOR_PROMPT + df['s_author_trim']\n",
        "  else:\n",
        "    dfc['source_text'] = TITLE_PROMPT + df['s_title_trim']\n",
        "  dfc['target_text'] = df['s_content_trim']\n",
        "  dfc = dfc[['source_text', 'target_text']]\n",
        "  return dfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7Owp1_aB4Cg"
      },
      "outputs": [],
      "source": [
        "df_author_title_content = build_dataset_df(my_df, True)\n",
        "df_author_title_content[100:105]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT5PfxPFDAlz"
      },
      "outputs": [],
      "source": [
        "df_title_content = build_dataset_df(my_df, False)\n",
        "df_title_content[100:105]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsAXpMJSDMdS"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.concat([df_author_title_content, df_title_content])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7UAy0RNDchP"
      },
      "outputs": [],
      "source": [
        "merged_df = merged_df.sample(frac=1.)\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_vxHg9MDqTj"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUt4xwq6Drrn"
      },
      "outputs": [],
      "source": [
        "# Quiet install simple T5 package\n",
        "!pip install -q simplet5 &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0NHrq6AD915"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from simplet5 import SimpleT5\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache() "
      ],
      "metadata": {
        "id": "XCLr4in62jmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg4u8ZfsEA85"
      },
      "outputs": [],
      "source": [
        "class MengziSimpleT5(SimpleT5):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    self.device = torch.device(\"cuda\")\n",
        "\n",
        "  def load_my_model(self, use_gpu: bool = True):\n",
        "    self.tokenizer = T5Tokenizer.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(\"Langboat/mengzi-t5-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcJmpBMLEFi4"
      },
      "outputs": [],
      "source": [
        "model = MengziSimpleT5()\n",
        "model.load_my_model()\n",
        "model.model = model.model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8ZQq6mYEHiO"
      },
      "outputs": [],
      "source": [
        "model.tokenizer(\"桥形通汉上，峰势接云危。</s>烟霞交隐映，花鸟自参差。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU7L1roeEPhY"
      },
      "outputs": [],
      "source": [
        "model.tokenizer.decode([1012, 955, 406, 921, 23, 3, 1440, 2180, 799, 355, 4008, 4, 1, 1448, 4152, 690, 3934, 4990, 3, 17544, 178, 2572, 769, 4, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXzTBimnFQbS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "merged_df = merged_df.sample(frac=1) # Shuffle\n",
        "train_df, eval_df = train_test_split(merged_df, test_size=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAVfp7sUOrv2"
      },
      "outputs": [],
      "source": [
        "print(\"train\", len(train_df), \"eval\", len(eval_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44fzxZP3EXoa"
      },
      "outputs": [],
      "source": [
        "model.train(train_df=train_df,\n",
        "            eval_df=eval_df, \n",
        "            source_max_token_len=(len(TITLE_PROMPT) + MAX_TITLE_CHAR +  1 + len(AUTHOR_PROMPT) + MAX_AUTHOR_CHAR),\n",
        "            target_max_token_len=MAX_CONTENT_CHAR, \n",
        "            batch_size=128,\n",
        "            max_epochs=3,\n",
        "            use_gpu=True,\n",
        "            outputdir=\"/content/drive/MyDrive/ML/Models/t5-poem-v2\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt3F93e+GNs+REZ239bHkc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}